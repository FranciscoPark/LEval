{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset('L4NLP/LEval', \"gsm100\", split='test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Show info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"len(data['input']) = {len(data['input'])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.random check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "item = random.choice(data)\n",
    "#print(item.keys())\n",
    "print(f\"doc:{item['input']}\")\n",
    "# for key in range(len(item['instructions'])):\n",
    "#     print(f\"instruction:{item['instructions'][key]}\")\n",
    "#     print(f\"output:{item['outputs'][key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "for d in data:\n",
    "    document = d['input']\n",
    "    document2 = \" \".join(document.split()[:10500])\n",
    "    print(num_tokens_from_string(document, \"gpt-3.5-turbo\"), num_tokens_from_string(document2, \"gpt-3.5-turbo\"))\n",
    "    # cnt = 0\n",
    "    # while num_tokens_from_string(document, \"gpt-3.5-turbo\") > 16000:\n",
    "    #     document = \" \".join(document.split()[:11000-cnt]) # chunk the input len into 16k tokens\n",
    "    #     cnt += 500\n",
    "    \n",
    "    # print(num_tokens_from_string(document, \"gpt-3.5-turbo\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_lora_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
