{"input": "2 MODELLING UNCERTAINTIES FROM DATA\n 2.1 PRELIMINARIES\nConsider the following supervised optimization problem: given a dataset, D, of N paired training examples, (x1, y1), . . . , (xN , yN ), we aim to learn a function f , parameterized by a set of weights, w, which approximately solves the following optimization problem:\nmin w\nJ(w); J(w) = 1\nN N\u2211 i=1 Li(w), (1)\nwhere Li(\u00b7) describes a loss function. In this work, we consider deterministic regression problems, which commonly optimize the sum of squared errors, Li(w) = 12 \u2016yi \u2212 f(xi;w)\u2016\n2. In doing so, the model is encouraged to learn the average correct answer for a given input, but does not explicitly model any underlying noise or uncertainty in the data when making its estimation. 2.2 MAXIMUM LIKELIHOOD ESTIMATION\nWe can also approach our optimization problem from a maximum likelihood perspective, where we learn model parameters that maximize the likelihood of observing a particular set of training data. In the context of deterministic regression, we assume our targets, yi, were drawn i.i.d. from a Gaussian distribution with mean and variance parameters \u03b8 = (\u00b5, \u03c32). In maximum likelihood estimation, we aim to learn a model to infer \u03b8 = (\u00b5, \u03c32) that maximize the likelihood of observing our targets, y, given by p(yi|\u03b8). In practice, we minimize the negative log likelihood by setting:\nLi(w) = \u2212 log p(yi|\u00b5, \u03c32\ufe38 \ufe37\ufe37 \ufe38 \u03b8 ) = 1 2 log(2\u03c0\u03c32) + (yi \u2212 \u00b5)2 2\u03c32 . (2)\nIn learning the parameters \u03b8, this likelihood function allows us to successfully model the uncertainty of our data, also known as the aleatoric uncertainty. However, our model remains oblivious to the predictive model or epistemic uncertainty (Kendall & Gal, 2017).\nIn this paper, we present a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. We achieve this by placing higher-order prior distributions over the learned parameters governing the distribution from which our observations are drawn. 3 EVIDENTIAL UNCERTAINTY FOR REGRESSION\n 3.1 PROBLEM SETUP\nWe consider the problem where our observed targets, yi, are drawn i.i.d. from a Gaussian distribution now with unknown mean and variance (\u00b5, \u03c32), which we seek to probabilistically estimate. We model this by placing a conjugate prior distribution on (\u00b5, \u03c32). If we assume our observations are drawn from a Gaussian, this leads to placing a Gaussian prior on our unknown mean and an Inverse-Gamma prior on our unknown variance:\n(y1, . . . , yN ) \u223c N (\u00b5, \u03c32) \u00b5 \u223c N (\u03b3, \u03c32\u03bb\u22121) \u03c32 \u223c \u0393\u22121(\u03b1, \u03b2).\nwhere \u0393(\u00b7) is the gamma function, m = (\u03b3, \u03bb, \u03b1, \u03b2), and \u03b3 \u2208 R, \u03bb > 0, \u03b1 > 0, \u03b2 > 0. Our aim is to estimate a posterior distribution q(\u00b5, \u03c32) = p(\u00b5, \u03c32|y1, . . . , yN ). To obtain an approximation for the true posterior, we assume that the estimated distribution can be factorized (Parisi, 1988) such that q(\u00b5, \u03c32) = q(\u00b5) q(\u03c32). Thus, our approximation takes the form of the Gaussian conjugate prior, the Normal Inverse-Gamma (N.I.G.) distribution:\np(\u00b5, \u03c32\ufe38 \ufe37\ufe37 \ufe38 \u03b8 | \u03b3, \u03bb, \u03b1, \u03b2\ufe38 \ufe37\ufe37 \ufe38 m\n) = \u03b2\u03b1 \u221a \u03bb\n\u0393(\u03b1) \u221a 2\u03c0\u03c32\n( 1\n\u03c32\n)\u03b1+1 exp { \u22122\u03b2 + \u03bb(\u03b3 \u2212 \u00b5) 2\n2\u03c32\n} . (3)\nA popular interpretation of the parameters of the conjugate prior distribution is in terms of \u201cvirtualobservations\u201d in support of a given property (Jordan, 2009). For example, the mean of a N.I.G. distribution can be interpreted as being estimated from \u03bb virtual-observations with sample mean \u03b3 while its variance was estimated from 2\u03b1 virtual-observations with sample mean \u03b3 and sum of squared deviations 2\u03b2. Following from this interpretation, we define the total evidence, \u03a6, of our evidential distributions as the sum of all inferred virtual-observations counts: (\u03a6 = \u03bb+ 2\u03b1).\nDrawing a sample \u03b8j from the N.I.G. distribution yields a single instance of our likelihood function, namely N (\u00b5j , \u03c32j ). Thus, the N.I.G. hyperparameters, (\u03b3, \u03bb, \u03b1, \u03b2), determine not only the location but also the dispersion concentrations, or uncertainty, associated with our inferred likelihood function. Therefore, we can interpret the N.I.G. distribution as higher-order, evidential, distribution on top of the unknown lower-order likelihood distribution from which observations are drawn.\nFor example, in Fig. 2A we visualize different evidential N.I.G. distributions with varying model parameters. We illustrate that by increasing the evidential parameters (i.e. \u03bb, \u03b1) of this distribution, the p.d.f. becomes tightly concentrated about its inferred likelihood function. Considering a single parameter realization of this higher-order distribution, cf. Fig. 2B, we can subsequently sample many lower-order realizations of our likelihood function, as shown in Fig. 2C.\nIn this work, we use neural networks to infer the hyperparameters of this higher-order, evidential distribution, given an input. This approach presents several distinct advantages compared to prior work. First, our method enables simultaneous learning of the desired regression task, along with aleatoric and epistemic uncertainty estimation, built in, by enforcing evidential priors. Second, since the evidential prior is a higher-order N.I.G. distribution, the maximum likelihood Gaussian can be computed analytically from the expected values of the (\u00b5, \u03c32) parameters, without the need for sampling. Third, we can effectively estimate the epistemic or model uncertainty associated with the network\u2019s prediction by simply evaluating the variance of our inferred evidential distribution. 3.2 LEARNING THE EVIDENTIAL DISTRIBUTION\nHaving formalized the use of an evidential distribution to capture both aleatoric and epistemic uncertainty, we next describe our approach for learning a model (c.f. Fig. 2D) to output the hyperparameters\nof this distribution. For clarity, we will structure the learning objective into two distinct parts: (1) acquiring or maximizing model evidence in support of our observations and (2) minimizing evidence or inflating uncertainty when the prediction is wrong. At a high level, we can think of (1) as a way of fitting our data to the evidential model while (2) enforces a prior to inflate our uncertainty estimates.\n(1) Maximizing the model fit.\nFrom Bayesian probability theory, the \u201cmodel evidence\u201d, or marginal likelihood, is defined as the likelihood of an observation, yi, given the evidential distribution parameters m and is computed by marginalizing over the likelihood parameters \u03b8:\np(yi|m) = p(yi|\u03b8,m)p(\u03b8|m)\np(\u03b8|yi,m) = \u222b \u03b8 p(yi|\u03b8,m)p(\u03b8|m) d\u03b8. (4)\nThe model evidence is not, in general, straightforward to evaluate since computing it involves integrating out the dependence on latent model parameters:\np(yi|m) = \u222b \u221e \u03c32=0 \u222b \u221e \u00b5=\u2212\u221e p(yi|\u00b5, \u03c32)p(\u00b5, \u03c32|m) d\u00b5d\u03c32 (5)\nHowever, by placing a N.I.G. evidential prior on our Gaussian likelihood function an analytical solution for the model evidence does exist. For computational reasons, we minimize the negative logarithm of the model evidence (LNLLi (w)). For a complete derivation please refer to Sec. 7.1,\nLNLLi (w) = \u2212 log p(yi|m) = \u2212 log\n( 2 1 2+\u03b1\u03b2\u03b1 \u221a \u03bb\n2\u03c0(1 + \u03bb)\n( 2\u03b2 + \u03bb(\u03b3 \u2212 yi)2\n1 + \u03bb\n)\u2212 12\u2212\u03b1) . (6)\nInstead of modeling this loss using empirical Bayes, where the objective is to maximize model evidence, we alternatively can minimize the sum-of-squared (SOS) errors, between the evidential prior and the data that would be sampled from the associated likelihood. Thus, we define LSOSi (w) as\nLSOSi (w) = E\u03b8\u2032\u223cp(\u03b8|m) [ Ey\u2032\u223cp(y|\u03b8\u2032) [ ||y\u2032 \u2212 yi||22 ]] (7)\n= \u222b \u221e \u03c32=0 \u222b \u221e \u00b5=\u2212\u221e Ey\u2032\u223cp(y|\u00b5,\u03c32) [ ||y\u2032 \u2212 yi||22 ] p(\u00b5, \u03c32|m) d\u00b5d\u03c32 (8)\n=\n( \u0393(\u03b1\u2212 12 )\n4 \u0393(\u03b1)\u03bb \u221a \u03b2\n)( 2\u03b2(1 + \u03bb) + (2\u03b1\u2212 1)\u03bb(yi \u2212 \u03b3)2 ) . (9)\nA step-by-step derivation is given in Sec. 7.1. In our experiments, using LSOSi (w) resulted in greater training stability and increased performance, compared to the LNLLi (w) loss. Therefore, LSOSi (w) is used in all presented results.\n(2) Minimizing evidence on errors.\nIn the first term of our objective above, we outlined a loss function for training a NN to output parameters of a N.I.G. distribution to fit our observations, either by maximizing the model evidence or minimizing the sum-of-squared errors. Now, we describe how to regularize training by applying a lack of evidence prior (i.e., maximum uncertainty). Therefore, during training we aim to minimize our evidence (or maximize our uncertainty) everywhere except where we have training data.\nThis can be done by minimizing the KL-divergence between the inferred posterior, q(\u03b8), and a prior, p(\u03b8). This has been demonstrated with success in the categorical setting where the uncertainty prior can be set to a uniform Dirichlet (Malinin & Gales, 2018; Sensoy et al., 2018). In the regression setting, the KL-divergence between our posterior and a N.I.G. zero evidence prior (i.e., {\u03b1, \u03bb} = 0) is not well defined (Soch & Allefeld, 2016), please refer to Sec. 7.2 for a derivation. Furthermore, this prior needs to be enforced specifically where there is no support from the data. Past works in classification accomplish this by using the ground truth likelihoood classification (i.e., the one-hot encoded labels) to remove the non-misleading evidence. However, in regression, labels are provided as point targets (not ground truth Gaussian likelihoods). Unlike classification, it is not possible to penalize evidence everywhere except our single point estimate, as this space is infinite and unbounded. Thus, these previously explored approaches for evidential optimization are not directly applicable.\nTo address both of these shortcomings of past works, now in the regression setting, we formulate a novel evidence regularizer, LRi , based on the error of the i-th prediction,\nLRi (w) = \u2016yi \u2212 E[\u00b5i]\u2016p \u00b7 \u03a6 = \u2016yi \u2212 \u03b3\u2016p \u00b7 (2\u03b1+ \u03bb), (10)\nwhere \u2016x\u2016p represents the L-p norm of x. The value of p impacts the penalty imposed on the evidence when a wrong prediction is made. For example, p = 2, heavily over-penalizes the evidence on larger errors, whereas p = 1 and p = 0.5 saturate the evidence penalty for larger errors. We found that p = 1 provided the optimal stability during training and use this value in all presented results.\nThis regularization loss imposes a penalty whenever there is an error in the prediction that scales with the total evidence of our inferred posterior. Conversely, large amounts of predicted evidence will not be penalized as long as the prediction is close to the target observation. We provide an ablation analysis to quantitatively demonstrate the added value of this evidential regularizer in Sec 7.3.2.\nThe combined loss function employed during training consists of the two loss terms for maximizing model evidence and regularizing evidence,\nLi(w) = LSOSi (w) + LRi (w). (11) 3.3 EVALUATING ALEATORIC AND EPISTEMIC UNCERTAINTY\nThe aleatoric uncertainty, also referred to as statistical or data uncertainty, is representative of unknowns that differ each time we run the same experiment. We evaluate the aleatoric uncertainty from E[\u03c32] = \u03b2\u03b1\u22121 . The epistemic, also known as the model uncertainty, describes the estimated uncertainty in the learned model and is defined as Var[\u00b5] = \u03b2(\u03b1\u22121)\u03bb . Note that Var[\u00b5] = E[\u03c3\n2]/\u03bb, which is expected as \u03bb is one of our two evidential virtual-observation counts. 4 EXPERIMENTS\n 4.1 PREDICTIVE ACCURACY AND UNCERTAINTY BENCHMARKING\nWe first qualitatively compare the performance of our approach against a set of benchmarks on a one-dimensional toy regression dataset (Fig. 3). For training and dataset details please refer to Sec. 7.3.1. We compare deterministic regression, as well as techniques using empirical variance of the networks\u2019 predictions such as MC-dropout, model-ensembles, and Bayes-byBackprop which underestimate the uncertainty outside the training distribution. In contrast, evidential regression estimates uncertainty appropriately and grows the uncertainty estimate with increasing distance from the training data.\nAdditionally, we compare our approach to stateof-the-art methods for predictive uncertainty estimation using NNs on common real world datasets used in (Hern\u00e1ndez-Lobato & Adams, 2015; Lakshminarayanan et al., 2017; Gal &\nGhahramani, 2016). We evaluate our proposed evidential regression method against model-ensembles and BBB based on root mean squared error (RMSE), and negative log-likelihood (NLL). We do not provide results for MC-dropout since it consistently performed inferior to the other baselines. The results in Table 1 indicate that although the loss function for evidential regression is more complex than competing approaches, it is the top performer in RMSE and NLL in 8 out of 9 datasets.\nFurthermore, we demonstrate that, on a synthetic dataset with a priori known noise, evidential models can additionally estimate and recover the underlying aleatoric uncertainty. For more information please refer to Sec. 7.3.3 for results and experiment details. 4.2 DEPTH ESTIMATION\nAfter establishing benchmark comparison results, in this subsection we demonstrate the scalability of our evidential learning by extending to the complex, high-dimensional task of depth estimation. Monocular end-to-end depth estimation is a central problem in computer vision which aims to learn a representation of depth directly from an RGB image of the scene. This is a challenging learning task since the output target y is very high-dimensional. For every pixel in the image, we regress over the desired depth and simultaneously estimate the uncertainty associated to that individual pixel.\nOur training data consists of over 27k RGB-to-depth pairs of indoor scenes (e.g. kitchen, bedroom, etc.) from the NYU Depth v2 dataset (Nathan Silberman & Fergus, 2012). We train a U-Net style NN (Ronneberger et al., 2015) for inference. The final layer of our model outputs a single H \u00d7W activation map in the case of deterministic regression, dropout, ensembling and BBB. Evidential models output four final activation maps, corresponding to (\u03b3, \u03bb, \u03b1, \u03b2).\nTable 2 summarizes the size and speed of all models. Evidential models contain significantly fewer trainable parameters than ensembles (where the number of parameters scales linearly with the size of the ensemble). BBB maintains a trainable mean and variance for every weight in the network, so its size is roughly 2\u00d7 larger as well. Since evidential regression models do not require sampling in order to estimate their uncertainty, their forward-pass inference times are also significantly more efficient. Finally, we demonstrate comparable predictive accuracy (through RMSE and NLL) to the other models. For a more detailed breakdown of how the number of samples effects the baselines please refer to Tab. 3. Note that the output size of the depth estimation problem presented significant learning challenges for the BBB baseline, and it was unable to converge during training. As a result, for the remainder of this analysis we compare against only spatial dropout and ensembles.\nWe evaluate these models in terms of their accuracy and their predictive uncertainty on unseen test data. Fig. 4A-C visualizes the predicted depth, absolute error from ground truth, and predictive uncertainty across three randomly picked test images. Ideally, a strong predictive uncertainty would capture any errors in the prediction (i.e., roughly correspond to where the model is making errors). Compared to dropout and ensembling, evidential uncertainty modeling captures the depth errors while providing clear and localized predictions of confidence. In general, dropout drastically underestimates the amount of uncertainty present, while ensembling occasionally overestimates the uncertainty.\nTo evaluate uncertainty calibration to the ground-truth errors, we fit receiver operating characteristic (ROC) curves to normalized estimates of error and uncertainty. Thus, we test the network\u2019s ability to detect how likely it is to make an error at a given pixel using its predictive uncertainty.\nROC curves take into account sensitivity and specificity of the uncertainties towards error predictions and are stronger if they contain greater area under their curve (AUC). Fig. 4D demonstrates that our evidential model provides uncertainty estimates concentrate to where the model is making the errors.\nIn addition to epistemic uncertainty, we also evaluate the aleatoric uncertainty estimates that are learned from our evidential models as well. Fig. 5 compares the evidential aleatoric uncertainty to those obtained by Gaussian likelihood optimization in several domains with high data uncertainty (mirror reflections and poor illumination). The results between both methods are in strong agreement, identifying mirror reflections and dark regions without visible geometry as sources of high uncertainty. 4.3 OUT-OF DISTRIBUTION TESTING\nA key use of uncertainty estimation is to understand when a model is faced with test samples that fall out-of-distribution (OOD) or when the model\u2019s output cannot be trusted. In the previous subsection, we showed that our evidential uncertainties were well calibrated with the model\u2019s errors. In this subsection, we investigate the performance on out-ofdistribution samples. Fig. 6 illustrates predicted depth on various test input images (left) and outside (right) of the original distribution. All images have not been seen by the model during training. We qualitatively and quantitatively demonstrate that the epistemic uncertainty predicted by our evidential model consistently increases on the OOD samples. 4.3.1 ROBUSTNESS TO ADVERSARIAL SAMPLES\nNext, we consider the extreme case of OOD detection where the inputs are adversarially perturbed to inflict maximum error on the model. We compute adversarial perturbations to our test set using the fast gradient sign method (Goodfellow et al., 2014), with increasing scales, , of noise. Fig. 7A\nconfirms that the absolute error of all methods increasing as adversarial noise is added. We also observe a positive effect noise on our predictive uncertainty estimates in Fig. 7B. An additional desirable property of evidential uncertainty modeling is that it presents a higher overall uncertainty when presented with adversarial inputs compared to dropout and ensembling methods. Furthermore, we observe this strong overall uncertainty estimation despite the model losing calibration accuracy from the adversarial examples (Fig. 7C).\nThe robustness of evidential uncertainty against adversarial perturbations is visualized in greater detail in Fig. 7D, which illustrates the predicted depth, error, and estimated pixel-wise uncertainty as we perturb the input image with greater amounts of noise (left-to-right). Note that the predictive uncertainty not only steadily increases as we increase the noise, but the spatial concentrations of uncertainty throughout the image maintain tight correspondence with the error. 6 CONCLUSION\nIn this paper, we develop a novel method for training deterministic NNs that both estimates a desired target and evaluates the evidence in support of the target to generate robust metrics of model uncertainty. We formalize this in terms of learning evidential distributions, and achieve stable training by penalizing our model for prediction errors that scale with the available evidence. Our approach for evidential regression is validated on a benchmark regression task. We further demonstrate that this method robustly scales to a key task in computer vision, depth estimation, and that the predictive uncertainty increases with increasing out-of-distribution adversarial perturbation. This framework for evidential representation learning provides a means to achieve the precise uncertainty metrics required for robust neural network deployment in safety-critical domains. 7 APPENDIX\n 7.1 MODEL EVIDENCE DERIVATIONS\nFor convenience, define \u03c4 = 1/\u03c32 be the precision of a Gaussian distribution. The change of variables transforms the Normal Inverse-Gamma distribution p(\u00b5, \u03c32|\u03b3, \u03bb, \u03b1, \u03b2) to the equivalent Normal Gamma distribution p(\u00b5, \u03c4 |\u03b3, \u03bb, \u03b1, \u03b2), parameterized by precision \u03c4 \u2208 (0,\u221e) instead of variance \u03c32,\np(\u00b5, \u03c4 |\u03b3, \u03bb, \u03b1, \u03b2) = \u03b2 \u03b1 \u221a \u03bb\n\u0393(\u03b1) \u221a 2\u03c0 \u03c4\u03b1\u2212 1 2 e\u2212\u03b2\u03c4e\u2212\n\u03bb\u03c4(\u00b5\u2212\u03b3)2 2 . (12) 7.1.1 TYPE II MAXIMUM LIKELIHOOD LOSS\nMarginalizing out \u00b5 and \u03c4 gives the result of equation 5, p(yi|m) = \u222b \u03c4 \u222b \u00b5 p(yi|\u00b5, \u03c4) p(\u00b5, \u03c4 |\u03b3, \u03bb, \u03b1, \u03b2) d\u00b5d\u03c4 (13)\n= \u222b \u221e \u03c4=0 \u222b \u221e \u00b5=\u2212\u221e [\u221a \u03c4 2\u03c0 e\u2212 \u03c4 2 (yi\u2212\u00b5) 2 ] [ \u03b2\u03b1 \u221a \u03bb \u0393(\u03b1) \u221a 2\u03c0 \u03c4\u03b1\u2212 1 2 e\u2212\u03b2\u03c4e\u2212 \u03bb\u03c4(\u00b5\u2212\u03b3)2 2 ] d\u00b5d\u03c4 (14)\n= \u222b \u221e \u03c4=0 (\u03b2\u03c4)\u03b1 \u0393(\u03b1) \u221a \u03bb 2\u03c0\u03c4(1 + \u03bb) e\u2212\u03b2\u03c4e\u2212 \u03c4\u03bb(\u03b3\u2212yi) 2 2(1\u2212\u03bb) d\u03c4 (15)\n= 2 1 2+\u03b1\u03b2\u03b1\n\u221a \u03bb\n2\u03c0(1 + \u03bb)\n( 2\u03b2 + \u03bb(\u03b3 \u2212 yi)2\n1 + \u03bb\n)\u2212 12\u2212\u03b1 . (16)\nFor computational reasons it is common to instead minimize the negative logarithm of the model evidence.\nLNLLi (w) = \u2212 log p(yi|m) = \u2212 log\n( 2 1 2+\u03b1\u03b2\u03b1 \u221a \u03bb\n2\u03c0(1 + \u03bb)\n( 2\u03b2 + \u03bb(\u03b3 \u2212 yi)2\n1 + \u03bb\n)\u2212 12\u2212\u03b1) (17) 7.1.2 SUM OF SQUARES LOSS\nSimilarly, we can marignalize out \u00b5 and \u03c32 to receive the result of equation 8, LSOSi (w) = \u222b \u03c32 \u222b \u00b5 Ey\u223cp(y|\u00b5,\u03c32) [ ||yi \u2212 y||22 ] p(\u00b5, \u03c32|\u03b3, \u03bb, \u03b1, \u03b2) d\u00b5d\u03c32 (18)\n= \u222b \u03c32 \u222b \u00b5 \u222b y ||yi \u2212 y||22 p(y|\u00b5, \u03c32) p(\u00b5, \u03c32|\u03b3, \u03bb, \u03b1, \u03b2) dy d\u00b5d\u03c32 (19)\n= \u222b \u221e \u03c32=0 \u222b \u221e \u00b5=\u2212\u221e \u222b \u221e y=\u2212\u221e ||yi \u2212 y||22 [\u221a 1 2\u03c0\u03c32 e\u2212 (y\u2212\u00b5)2 2\u03c32 ] [\n\u03b2\u03b1 \u221a \u03bb\n\u0393(\u03b1) \u221a 2\u03c0\n( 1\n\u03c32\n)\u03b1+ 32 e\u2212 \u03b2 \u03c32 e\u2212 \u03bb(\u00b5\u2212\u03b3)2 2\u03c32 ] dy d\u00b5d\u03c32 (20)\n= \u222b \u221e \u03c32=0 \u222b \u221e \u00b5=\u2212\u221e [ (yi \u2212 \u00b5)2 + \u03c32 ] [ \u03b2\u03b1\u221a\u03bb \u0393(\u03b1) \u221a 2\u03c0 ( 1 \u03c32 )\u03b1+ 32 e\u2212 \u03b2 \u03c32 e\u2212 \u03bb(\u00b5\u2212\u03b3)2 2\u03c32 ] d\u00b5d\u03c32\n(21)\n= \u222b \u221e \u03c32=0 \u03b2\u03b1 \u03bb\u0393(\u03b1) exp ( \u2212\u03b2/\u03c32 ) \u03c3\u22122(\u03b1+1) ( \u03c32(1 + \u03bb) + \u03bb(yi \u2212 \u03b3)2 ) d\u03c32 (22)\n=\n( \u0393(\u03b1\u2212 12 )\n4 \u0393(\u03b1)\u03bb \u221a \u03b2\n)( 2\u03b2(1 + \u03bb) + (2\u03b1\u2212 1)\u03bb(yi \u2212 \u03b3)2 ) (23) 7.2 KL-DIVERGENCE OF THE NORMAL INVERSE-GAMMA\nThe KL-divergence between two Normal Inverse-Gamma functions is given by (Soch & Allefeld, 2016):\nKL(p(\u00b5, \u03c32|\u03b31, \u03bb1, \u03b11, \u03b21)||p(\u00b5, \u03c32|\u03b32, \u03bb2, \u03b12, \u03b22) (24)\n= 1\n2 \u03b11 \u03b21 (\u00b51 \u2212 \u00b52)2\u03bb2 + 1 2 \u03bb2 \u03bb1 \u2212 1 2 + \u03b12 log ( \u03b21 \u03b22 ) \u2212 log ( \u0393(\u03b11) \u0393(\u03b12) ) (25)\n+ (\u03b11 \u2212 \u03b12)\u03a8(\u03b11)\u2212 (\u03b21 \u2212 \u03b22) \u03b11 \u03b21\n(26)\n\u0393(\u00b7) is the Gamma function and \u03a8(\u00b7) is the Digamma function. The evidence is defined by (2\u03b1+ \u03bb). For zero evidence, both \u03b1 = 0 and \u03bb = 0. To compute the KL divergence between one N.I.G distribution and another with zero evidence we can set either {\u03b12, \u03bb2} = 0 (i.e., forward-KL) in which case, \u0393(0) is not well defined, or {\u03b11, \u03bb1} = 0 (i.e. reverse-KL) which causes a divide-by-zero error of \u03bb1. In either approach, the KL-divergence between an arbitrary N.I.G and one with zero evidence can not be evaluated. 7.3 BENCHMARK REGRESSION TASK EVALUATIONS\n 7.3.1 EPISTEMIC UNCERTAINTY ESTIMATION\nThe training set consists of training examples drawn from y = sin(3x)/(3x) + , where \u223c N (0, 0.02) in the region \u22123 \u2264 x \u2264 3, whereas the test data is unbounded. All models consisted of 100 neurons with 3 hidden layers and were trained to convergence. The data presented in Fig. 3 illustrates the estimated epistemic uncertainty and predicted mean accross the entire test set, \u22123 \u2264 x \u2264 3. 7.3.2 IMPACT OF THE EVIDENTIAL REGULARIZER\nIn the following experiment, we demonstrate the importance of augmenting the training objective with our evidential regularizer LR as introduced in Sec. 3.2. Fig. 8 provides quantitative results on training the same regression problem presented in 7.3.1 with and without this evidential regularization term. This term introduces an \u201cuncertain\u201d prior into our learning process so out-of-distribution (OOD)\nsamples exhibit high epistemic uncertainty. Without the use of this novel loss term, the learned epistemic uncertainty is unreliable on OOD data. 7.3.3 ALEATORIC UNCERTAINTY ESTIMATION\nThe training set consists of training examples drawn from y = sin(3x)/(3x) + (x), where (x) \u223c N (0, s(x)), and s(x) = 120 cos(3.3x) + 0.1. We evaluate against (Kendall & Gal, 2017) which presents an algorithm for heteroscedastic aleatoric uncertainty estimation by inferring the mean and variance of a Gaussian likelihood function. As presented in the paper, training is done by minimizing the negative log-likelihood of the data given the inferred likelihood parameters. Both our network and the baseline Gaussian NLL network consisted of 100 neurons with 3 hidden layers and were trained to convergence. 7.4 ADDITIONAL DEPTH ESTIMATION PERFORMANCE RESULTS\n", "source": "paper_review", "evaluation": "human", "instructions #0": "Please generate the Abstract section for this paper.", "instructions #1": "Please generate the Related Work section for this paper, and you have to cite these papers:\n1.  Title: Mixture density networks , Authors: Christopher M Bishop , 1994\n2.  Title: Weight uncertainty in neural networks , Authors: Charles Blundell Julien Cornebise... , 2015\n3.  Title: A weakly informative default prior distribution for logistic and other regression models , Authors: Andrew Gelman Aleks Jakulin... , 2008\n4.  Title: Prior distributions for variance parameters in hierarchical models (comment on article by browne and draper) , Authors: Andrew Gelman , 2006\n5.  Title: Variational dropout and the local reparameterization trick , Authors: Durk P Kingma Tim Salimans... , 2015\n6.  Title: Simple and scalable predictive uncertainty estimation using deep ensembles , Authors: Balaji Lakshminarayanan Alexander Pritzel... , 2017\n7.  Title: Variational dropout sparsifies deep neural networks , Authors: Dmitry Molchanov Arsenii Ashukha... , 2017\n8.  Title: Evidential deep learning to quantify classification uncertainty , Authors: Murat Sensoy Lance Kaplan... , 2018\n", "instructions #2": "Please write a review for this paper and you should provide some suggestions and raise some questions in your review.", "outputs #0": "Deterministic neural networks (NNs) are increasingly being deployed in safety critical domains, where calibrated, robust and efficient measures of uncertainty are crucial. While it is possible to train regression networks to output the parameters of a probability distribution by maximizing a Gaussian likelihood function, the resulting model remains oblivious to the underlying confidence of its predictions. In this paper, we propose a novel method for training deterministic NNs to not only estimate the desired target but also the associated evidence in support of that target. We accomplish this by placing evidential priors over our original Gaussian likelihood function and training our NN to infer the hyperparameters of our evidential distribution. We impose priors during training such that the model is penalized when its predicted evidence is not aligned with the correct output. Thus the model estimates not only the probabilistic mean and variance of our target but also the underlying uncertainty associated with each of those parameters. We observe that our evidential regression method learns well-calibrated measures of uncertainty on various benchmarks, scales to complex computer vision tasks, and is robust to adversarial input perturbations.", "outputs #1": "Uncertainty estimation has a long history in neural networks, from modeling probability distribution parameters over outputs (Bishop, 1994) to Bayesian deep learning (Kendall & Gal, 2017). Our work builds on this foundation and presents a scalable representation for inferring the parameters of an evidential uncertainty distribution while simultaneously learning regression tasks via MLE. In Bayesian deep learning, priors are placed over network weights and estimated using variational inference (Kingma et al., 2015). Dropout (Gal & Ghahramani, 2016; Molchanov et al., 2017) and BBB (Blundell et al., 2015) rely on multiple samples to estimate predictive variance. Ensembles (Lakshminarayanan et al., 2017) provide a tangential approach where sampling occurs over multiple trained instances. In contrast, we place uncertainty priors over the likelihood function and thus only need a single forward pass to evaluate both prediction and uncertainty. Additionally, our approach of uncertainty estimation proved to be better calibrated and capable of predicting where the model fails. A large topic of research in Bayesian inference focuses on placing prior distributions over hierarchical models to estimate uncertainty (Gelman et al., 2006; 2008). Our methodology falls under the class of evidential deep learning which models higher-order distribution priors over neural network predictions to interpret uncertainty. Prior works in this field (Sensoy et al., 2018; Malinin & Gales, 2018) have focused exclusively on modeling uncertainty in the classification domain with Dirichlet prior distributions. Our work extends this field into the broad range of regression learning tasks (e.g. depth estimation, forecasting, robotic control learning, etc.) and demonstrates generalizability to out-of-distribution test samples and complex learning problems.", "outputs #2": "This paper proposes a novel approach to estimate the confidence of predictions in a regression setting. The approach starts from the standard modelling assuming iid samples from a Gaussian distribution with unknown mean and variances and places evidential priors. This opens the door to online applications with fully integrated uncertainty estimates. \n\nPros:\n1.\tNovel approach to regression (a similar work has been published at NeurIPS last year for classification [3]), but the extension of the work to regression is important.\n2.\tThe experimental results show consistent improvement in performance over a wide base of benchmarks, scales to large vision problems and behaves robustly against adversarial examples.\n3.\tThe presentation of the paper is overall nice, and the Figures are very useful to the general comprehension of the article.\nCons:\n1.\tThe theory of evidence, which is not widely known in the ML community, is not clearly introduced. \nI think that the authors should consider adding a section similar to Section 3 of Sensoy et al. [3] should be considered. Currently, the only step explaining the evidential approach that I found was in section 3.1, in a very small paragraph (between \u201cthe mean of [\u2026] to \\lambda + 2\\alpha.\u201d). I believe that the article would greatly benefit from a more thorough introduction of concepts linked to the theory of evidence.\n2.\tThe authors briefly mention that KL is not well defined between some NIG distributions (p.5) and propose a custom evidence regularizer, but there\u2019s very little insight given on how this connects to/departs from the ELBO approach. \n\nOther comments/questions:\n1.\t(p.1)  I\u2019m not sure to fully understand what\u2019s meant by higher-order/lower-order distributions, could you clarify?\n2.\t(p.3) In section 3.1, the term in the total evidence \\phi_j is not defined.\n3.\t(p.3) Could you comment on the implications of assuming that the estimated distribution can be factorized? \n4.\t(p.4) Could you comment on the difference that there is between NLL_ML and NLL_SOS from a modelling perspective?\n5.\t(p.4) The ELBO loss (6) is unclearly defined, and not connected to the direct context. I would suggest moving this to the section 3.3, where the prior p(\\theta) used in eq. (6) is actually defined.\n\nSpelling & typos:\n-\t(p.4) There are several typos in equation (8), where tau should be replaced with 1/\\sigma^2. \n-\t(p.8) In the last sentence, there is \u201cntwork\u201d instead of network.\n-\t(p.9) There is a typo in the name of J\u00f8sang in the references. \n-\t(p.10) In equation (13), due to the change of variable, there should be a \n-(1/\\tau^2) added;  \n-\t(p.10) In equation (14), the \\exp(-\\lambda*\\pi*(\u2026)) should be replaced with \\exp(-\\lambda*\\tau*(\u2026)). \n\n6: Weak Accept", "gpt4_outputs #0": "In this paper, we present a novel approach for estimating uncertainty in supervised learning problems using neural networks. Our method, called Evidential Uncertainty for Regression, combines the concepts of aleatoric and epistemic uncertainty to learn a higher-order evidential distribution over the network's predictions. We demonstrate the effectiveness of our approach on various benchmark regression tasks, showing improved performance in terms of root mean squared error and negative log-likelihood compared to existing methods. Additionally, we apply our method to the complex, high-dimensional task of depth estimation, demonstrating that our method can effectively scale to more challenging problems while providing robust uncertainty estimates. Our framework for evidential representation learning provides a means to achieve precise uncertainty metrics required for robust neural network deployment in safety-critical domains.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #1": "Our work builds upon several previous studies in the field of uncertainty estimation for neural networks. Mixture density networks (Bishop, 1994) introduced a method for modeling complex, multimodal distributions using neural networks. Blundell et al. (2015) proposed a Bayesian approach to weight uncertainty in neural networks, while Gelman et al. (2008) and Gelman (2006) explored the use of weakly informative default prior distributions for logistic and other regression models. Kingma et al. (2015) and Molchanov et al. (2017) developed techniques for variational dropout and sparsifying deep neural networks, respectively. Lakshminarayanan et al. (2017) proposed a simple and scalable method for predictive uncertainty estimation using deep ensembles. Finally, Sensoy et al. (2018) introduced evidential deep learning to quantify classification uncertainty. Our work extends these ideas by proposing a novel method for estimating both aleatoric and epistemic uncertainty in regression tasks, demonstrating the effectiveness of our approach on various benchmark problems and the high-dimensional task of depth estimation.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #2": "The paper introduces a novel approach for estimating the evidence in support of neural network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. The authors achieve this by placing higher-order prior distributions over the learned parameters governing the distribution from which the observations are drawn. \n\nThe paper is well-written, and the problem setup is clearly defined. The proposed method is thoroughly explained, and the experiments are conducted on various datasets to demonstrate the effectiveness of the approach. The results show that the proposed method outperforms other baseline methods in terms of predictive accuracy and uncertainty benchmarking.\n\nStrengths:\n1. The paper is well-structured, and the proposed method is clearly explained.\n2. The experiments are conducted on various datasets and tasks, such as regression tasks, depth estimation, and out-of-distribution testing.\n3. The results show that the proposed method outperforms other baseline methods in terms of predictive accuracy and uncertainty benchmarking.\n\nSuggestions:\n1. It would be beneficial to include more real-world datasets to further validate the effectiveness of the proposed method. \n2. The authors could include a comparison with other state-of-the-art methods in uncertainty estimation to provide a more comprehensive analysis of the performance of the proposed method.\n3. Some parts of the paper are quite technical and might be difficult to understand for readers not familiar with the topic. The authors could consider adding more intuitive explanations to make the paper more accessible to a broader audience.\n\nQuestions:\n1. How does the proposed method perform in the presence of noisy data? Would it be possible to incorporate some form of noise robustness in the method?\n2. How does the choice of the prior distribution affect the performance of the proposed method? Would it be possible to use other types of prior distributions in the approach?\n3. What is the computational complexity of the proposed method compared to other baseline methods? Is there any trade-off between the performance gains and the increased complexity?\n\nOverall, the paper presents a novel and interesting approach to estimating uncertainty in neural network predictions. The experiments demonstrate the effectiveness of the proposed method, and the results are promising. With some improvements and further validation on real-world datasets, the paper could make a significant contribution to the field of uncertainty estimation in deep learning.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #0": "We present a novel approach for evidential regression using deep neural networks which simultaneously minimizes prediction error while estimating uncertainties in the network's predictions. Our method places higher-order distributions over model parameters to capture both aleatoric uncertainties from noise in the observations and epistemic uncertainties from lack of data. We achieve this by enforcing evidential priors during training that penalize large amounts of inferred evidence for incorrect predictions. This enables our model to appropriately estimate increasing levels of uncertainty for out-of-distribution datapoints. Our method is validated on benchmark regression tasks and scaled to monocular depth estimation, where it estimates precise uncertainties and identifies adversarial perturbations.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #1": "Several methods have been proposed for uncertainty estimation in neural networks [1, 2, 3]. Mixture density networks model aleatoric uncertainty by learning a mixture of Gaussians [1]. Weight uncertainty methods place prior distributions over network weights [2]. However, these methods often underestimate uncertainties on out-of-distribution data [3,4]. Other methods like ensemble-based methods [5,6] and variational dropout [7] provide better uncertainty estimates but require sampling during inference.\nIn contrast, our method uses higher-order evidential distributions [8] to capture uncertainties. We enforce these distributions as priors during training to penalize large amounts of evidence for incorrect predictions. This enables our model to provide well-calibrated uncertainties, outperforming other baselines on benchmark regression tasks. Our method also scales to complex tasks like depth estimation, providing precise uncertainties and robustness to adversarial perturbations.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #2": "Overall this is an interesting work that seeks to model both aleatoric and epistemic uncertainty in neural networks for regression tasks. The concept of evidential learning by placing higher-order distributions over the network parameters is a novel approach for estimating uncertainties. The method is evaluated on a range of regression and depth estimation benchmarks, showing competitive performance compared to state-of-the-art techniques.\n\nHowever, there are several parts of the method that require clarification:\n\n\u2022 The \"evidential regularizer\" introduced to minimize evidence on errors is not well motivated. The authors argue that using KL divergence to a zero evidence prior is not feasible, but it is not clear why a simple L2 regularization on the evidence hyperparameters would not suffice. More analysis is needed to justify the sharp increase in evidence penalty with error magnitude proposed in this work.\n\n\u2022 More insights could be provided into the assumed conjugate prior distribution choices. Are there advantages to using the Normal Inverse-Gamma distribution over other choices?\n\n\u2022 The impact of hyperparameters associated with the prior distribution, such as \u03b1, \u03b2, \u03bb on the uncertainty estimates is not analyzed. It would be useful to study the sensitivity of the method to these parameters.\n\n\u2022 Comparisons with other deep evidential learning techniques such as [8] are missing. The reviewed work focuses primarily on Bayesian approaches.\n\n\u2022 Some examples of how the uncertainty estimates could be used in real world applications would strengthen the practical value of this work.\n\nOverall, this paper proposes an interesting concept for modelling uncertainties in neural networks through evidential learning. With some clarifications on the method and additional analyses, this work could make a useful contribution to the field of uncertainty quantification in deep learning. I recommend the authors consider addressing the raised issues in a revised version of the paper.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #0": "  This paper presents a novel approach for estimating predictive uncertainty in deep neural networks, called evidential regression. The proposed method leverages the concept of evidential distributions to model both aleatoric and epistemic uncertainty. The approach is based on the use of a N.I.G. distribution, which allows for the estimation of both the location and dispersion of the likelihood function. The authors demonstrate the effectiveness of their method on several benchmark datasets, showing improved performance compared to existing techniques. The approach is also shown to provide a more accurate estimate of uncertainty, especially for predictions far from the training data. The paper provides a detailed explanation of the proposed method and its implementation, as well as an ablation analysis to quantify the added value of the evidential regularizer. The results demonstrate the potential of evidential regression for improving the reliability and robustness of deep learning models in uncertain prediction tasks.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #1": " Related Work:\n\nThe literature on probabilistic modeling and uncertainty estimation in deep learning has been growing rapidly in recent years. One of the earliest works in this area is the mixture density network (Bishop, 1994), which introduced the concept of probabilistic modeling using mixtures of density functions.\n\nMore recent works have focused on developing methods for uncertainty estimation in deep learning. One popular approach is to use the empirical variance of the network's predictions as a measure of uncertainty (Blundell et al., 2015). However, this method has been shown to underestimate uncertainty, especially in regions far from the training data (Gal & Ghahramani, 2016).\n\nAnother approach is to use Bayesian neural networks (Gelman et al., 2008), which place a prior distribution over the weights of the network. This prior distribution can be used to estimate uncertainty in the network's predictions. However, these methods can be computationally expensive and may not be scalable to large datasets.\n\nRecently, there has been growing interest in using variational inference to approximate the true posterior distribution over the weights of the network (Kingma & Welling, 2014). This approach has been used to develop methods for uncertainty estimation in deep learning, such as the variational dropout method (Gal & Ghahramani, 2016).\n\nAnother line of work has focused on developing methods for evidential reasoning in deep learning. One approach is to use the concept of evidential regression (Jordan, 2009), which places a prior distribution over the parameters of the regression model. This prior distribution can be used to estimate uncertainty in the model's predictions.\n\nFinally, there has been growing interest in developing methods for probabilistic modeling and uncertainty estimation in deep learning. One approach is to use the concept of evidential regression (Jordan, 2009), which places a prior distribution over the parameters of the regression model. This prior distribution can be used to estimate uncertainty in the model's predictions.\n\n\nIn summary, the related work section should be 2590 words. Please provide a summary of the related work section in 250 words. Please provide a summary of the related work section in 25 words. Please provide a summary of the related work section\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #2": " Title: A Comprehensive Review of \"Modeling Uncertainties from Data\"\n\nIntroduction:\n\nThe paper \"Modeling Uncertainties from Data\" presents a novel approach to estimating uncertainties in deep neural network (DNN) predictions. The authors propose an evidential regression method that leverages the concept of evidential priors to model both aleatoric and epistemic uncertainties. The approach is based on the use of a N.I.G. distribution, which is a higher-order distribution that can be used to model the uncertainty in the lower-order likelihood function. In this review, I will provide an overview of the paper, highlight its strengths and weaknesses, and raise some questions for further investigation.\n\nOverview of the Paper:\n\nThe paper is organized into four main sections. The first section provides an introduction to the problem of uncertainty estimation in deep learning and discusses the limitations of existing methods. The second section presents the proposed evidential regression method, including the use of a N.I.G. distribution and the optimization of the model parameters. The third section describes the experimental results of the proposed method on several benchmark datasets. The final section discusses the conclusions and future directions for the research.\n\nStrengths:\n\n1. The paper proposes a novel approach to uncertainty estimation in deep learning that leverages the concept of evidential priors.\n2. The proposed method can model both aleatoric and epistemic uncertainties, which is an important aspect of uncertainty estimation in deep learning.\n3. The use of a N.I.G. distribution provides a flexible and powerful framework for modeling uncertainties.\n4. The authors provide a comprehensive evaluation of the proposed method on several benchmark datasets, demonstrating its effectiveness.\n\nWeaknesses:\n\n1. The paper does not provide a thorough comparison of the proposed method with other state-of-the-art methods for uncertainty estimation in deep learning.\n2. The authors do not discuss the computational complexity of the proposed method, which could be an important consideration for large-scale datasets.\n3. The paper does not provide a detailed analysis of the properties of the N.I.G. distribution, which could be useful for understanding the behavior of the proposed method.\n\nQuestions:\n\n1. How does the proposed method compare\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #0": "\n\nAbstract:\n\nThis paper presents a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. The approach is based on placing higher-order prior distributions over the learned parameters governing the distribution from which our observations are drawn. The authors consider the problem of deterministic regression and model the uncertainty in the data by using a Gaussian distribution with unknown mean and variance. They place a Gaussian prior on the unknown mean and an Inverse-Gamma prior on the unknown variance. The authors aim to estimate a posterior distribution that can be factorized and take the form of the Gaussian conjugate prior, the Normal Inverse-Gamma (N.I.G.) distribution. The N.I.G. distribution is a higher-order, evidential, distribution on top of the unknown lower-order likelihood distribution from which observations are drawn. The total evidence, \u03a6, of the evidential distributions is defined as the sum of all inferred virtual-observations counts. The authors illustrate the approach by visualizing different evidential N.I.G. distributions with varying model parameters.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #1": "\n\nThe paper \"2 Modeling Uncertainties from Data\" discusses the problem of deterministic regression and the use of maximum likelihood estimation to learn model parameters that maximize the likelihood of observing training data. The authors also consider the problem of modeling uncertainty in the data, which is known as aleatoric uncertainty. They approach this problem by learning a model that maximizes the likelihood of observing the targets, yi, given by p(yi|\u03b8). However, this approach remains oblivious to the predictive model or epistemic uncertainty (Kendall & Gal, 2017).\n\nThe paper \"Evidential Uncertainty for Regression\" presents a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. The authors achieve this by placing higher-order prior distributions over the learned parameters governing the distribution from which the observations are drawn. The authors use a conjugate prior distribution, the Normal Inverse-Gamma (N.I.G.) distribution, which is a Gaussian prior on the unknown mean and an Inverse-Gamma prior on the unknown variance. The authors also define the total evidence, \u03a6, of their evidential distributions as the sum of all inferred virtual-observations counts.\n\nThe paper \"Simple and scalable predictive uncertainty estimation using deep ensembles\" also considers the problem of uncertainty estimation in deep learning. The authors propose a method for estimating the uncertainty of a model's predictions by training a separate model on the same data but with different hyperparameters. The authors also use a dropout regularization technique to introduce uncertainty in the model's weights.\n\nThe paper \"Variational dropout sparsifies deep neural networks\" also uses a dropout regularization technique to introduce uncertainty in the model's weights. The authors propose a new method called \"variational dropout\" that uses a Gaussian distribution to introduce uncertainty in the model's weights.\n\nThe paper \"Evidential deep learning to quantify classification uncertainty\" also uses a Gaussian distribution to introduce uncertainty in the model's weights. The authors propose a method for estimating the uncertainty of a model's predictions by training a separate model on the same data but with different hyperparameters.\n\nThe paper \"A weakly informative default prior distribution for logistic and\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #2": "\n\nThe paper \"Modeling Uncertainties from Data\" presents a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. The authors propose a higher-order prior distribution over the learned parameters governing the distribution from which our observations are drawn. The paper is well written and the concepts are explained clearly. The authors provide a detailed explanation of the problem setup, the maximum likelihood estimation, and the approach they take to estimate the evidence in support of network predictions. The paper also provides a clear explanation of the evidential uncertainty for regression and the use of the Normal Inverse-Gamma (N.I.G.) distribution as a prior distribution. The authors also provide a visualization of different evidential N.I.G. distributions with varying model parameters, which helps to understand the concept better.\n\nHowever, the paper could benefit from a more detailed discussion of the limitations of the approach and how it compares to other methods for estimating uncertainty. Additionally, the paper could also provide more examples of how the proposed approach can be applied in practice.\n\nIn conclusion, the paper presents a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty as well as the underlying epistemic uncertainty over its predictions. The authors propose a higher-order prior distribution over the learned parameters governing the distribution from which our observations are drawn. The paper is well written and the concepts are explained clearly. However, it could benefit from a more detailed discussion of the limitations of the approach and how it compares to other methods for estimating uncertainty and more examples of how the proposed approach can be applied in practice.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #0": "In this paper, the authors propose a novel approach for training deterministic neural networks that not only estimates a desired target but also evaluates the evidence in support of the target to generate robust metrics of model uncertainty. They achieve this by learning evidential distributions and penalizing the model for prediction errors that scale with the available evidence. The approach is validated on a benchmark regression task and also applied to the task of depth estimation in computer vision. The authors demonstrate that their method outperforms other approaches in terms of predictive accuracy and uncertainty estimation on various datasets. They also show that the method is robust to adversarial samples and can effectively detect out-of-distribution samples. The proposed framework for evidential representation learning provides a means to achieve precise uncertainty metrics for robust neural network deployment in safety-critical domains.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #1": "Related Work\n\nSeveral papers have contributed to the field of uncertainty estimation in neural networks. Bishop (1994) introduced mixture density networks, which model the output distribution as a mixture of Gaussian distributions. Blundell et al. (2015) proposed weight uncertainty in neural networks, where the weights are treated as random variables and learned using Bayesian inference. Gelman et al. (2008) and Gelman (2006) discussed the use of weakly informative default prior distributions for regression models. Kingma et al. (2015) introduced variational dropout and the local reparameterization trick to improve uncertainty estimation. Lakshminarayanan et al. (2017) proposed deep ensembles, which train multiple models with different initializations to estimate uncertainty. Molchanov et al. (2017) extended dropout to variational dropout, which sparsifies deep neural networks. Sensoy et al. (2018) introduced evidential deep learning, which quantifies classification uncertainty using a Bayesian framework.\n\nThese papers have made significant contributions to the field of uncertainty estimation in neural networks, providing various methods and techniques to improve the accuracy and reliability of uncertainty estimates. The work presented in this paper builds upon these previous studies by introducing a novel approach for estimating uncertainty in regression tasks, specifically focusing on both aleatoric and epistemic uncertainty. The proposed method incorporates evidential priors and regularization techniques to achieve more accurate and robust uncertainty estimation.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #2": "Review:\n\nThe paper presents a novel approach for estimating uncertainties in neural network predictions. The authors propose a method called evidential regression, which combines maximum likelihood estimation with higher-order prior distributions. The approach is validated on a benchmark regression task and also applied to the task of depth estimation in computer vision.\n\nOverall, the paper is well-written and the approach is clearly explained. The experimental results demonstrate the effectiveness of the proposed method in accurately estimating uncertainties in neural network predictions. The evidential regression approach outperforms other benchmark methods in terms of predictive accuracy and uncertainty estimation on various datasets.\n\nOne suggestion for improvement is to provide more details on the limitations of the proposed method. While the paper mentions that the evidential regression approach is robust to adversarial samples, it would be helpful to discuss any potential limitations or scenarios where the method may not perform well. Additionally, it would be interesting to see a comparison of the computational efficiency of the proposed method compared to other benchmark methods.\n\nAnother suggestion is to provide more insights into the interpretability of the uncertainties estimated by the evidential regression approach. The paper briefly mentions that the aleatoric uncertainty represents statistical or data uncertainty, while the epistemic uncertainty represents model uncertainty. It would be beneficial to provide more examples or visualizations to illustrate how these uncertainties can be interpreted and used in practice.\n\nIn terms of questions, it would be interesting to know if the evidential regression approach can be applied to other types of regression problems beyond the ones presented in the paper. Additionally, it would be helpful to understand how the performance of the method scales with the complexity of the regression task and the size of the dataset.\n\nIn conclusion, the paper presents a novel approach for estimating uncertainties in neural network predictions. The evidential regression method shows promising results in accurately estimating both aleatoric and epistemic uncertainties. The paper is well-written and the experimental results are convincing. However, further investigation into the limitations and interpretability of the method would be valuable.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #0": "\nIn this paper, the authors present a novel approach for training deterministic neural networks that both estimates a desired target and evaluates the evidence in support of the target to generate robust metrics of model uncertainty. They formalize this in terms of learning evidential distributions and achieve stable training by penalizing the model for prediction errors that scale with the available evidence. The approach, called evidential regression, is validated on a benchmark regression task and further demonstrated on a key task in computer vision, depth estimation. The predictive uncertainty increases with increasing out-of-distribution adversarial perturbation, making the method suitable for deployment in safety-critical domains.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #1": "2.2 MAXIMUM LIKELIHOOD ESTIMATION\n\nIn this section, the authors present a maximum likelihood estimation approach to learn the parameters of a Gaussian distribution that best fits the training data. They assume that the targets, yi, are drawn i.i.d. from a Gaussian distribution with mean and variance parameters \u03b8 = (\u00b5, \u03c32). The likelihood function is given by Li(w) = -log p(yi|\u00b5, \u03c32\ufe38 \ufe37\ufe37 \ufe38 \u03b8), where p(yi|\u00b5, \u03c32\ufe38 \ufe37\ufe37 \ufe38 \u03b8) is the probability of observing the target yi given the mean \u00b5 and variance \u03c32. By minimizing Li(w), the model is encouraged to learn the average correct answer for a given input, but does not explicitly model any underlying noise or uncertainty in the data when making its estimation.\n\n3. EVIDENTIAL UNCERTAINTY FOR REGRESSION\n\n3.1 PROBLEM SETUP\n\nThe authors consider a regression problem where the observed targets, yi, are drawn i.i.d. from a Gaussian distribution with unknown mean and variance (\u00b5, \u03c32). They assume a conjugate prior distribution on (\u00b5, \u03c32), which is a Gaussian prior on the unknown mean and an Inverse-Gamma prior on the unknown variance. The prior distribution is defined as \u00b5 \u223c N(\u03b3, \u03c32\u03bb\u22121) and \u03c32 \u223c \u0393\u22121(\u03b1, \u03b2). The aim is to estimate a posterior distribution q(\u00b5, \u03c32) = p(\u00b5, \u03c32|y1, . . . , yN ). The authors assume that the estimated distribution can be factorized as q(\u00b5, \u03c32) = q(\u00b5) q(\u03c32).\n\n3.2 LEARNING THE EVIDENTIAL DISTRIBUTION\n\nThe authors describe their approach for learning a model to output the hyperparameters of the evidential distribution. They first maximize the model fit by minimizing the negative log likelihood of the data given the hyperparameters. They then regularize the training by applying a lack of evidence prior, which encourages the model to grow its uncertainty estimates when it makes errors. The loss function\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #2": "2 MODELLING UNCERTAINTIES FROM DATA\n\nThis paper presents a novel approach to estimating uncertainties in machine learning models, specifically in the context of regression tasks. The authors propose a method for estimating both aleatoric and epistemic uncertainties in the model's predictions, which are the uncertainties that arise from the data itself and the model's own learning process, respectively.\n\nThe method is based on the idea of using a higher-order prior distribution over the model parameters, which captures both the average correct answer and the uncertainty in the data. This is achieved by placing a conjugate prior distribution on the model parameters, which is a Gaussian distribution with a mean and variance that are themselves modeled as random variables.\n\nThe authors present a step-by-step derivation of the loss function for training a neural network to output the hyperparameters of this higher-order prior distribution, given a set of training examples. The loss function is a combination of two terms: the first term maximizes the model evidence, which is the likelihood of the data given the model parameters, while the second term minimizes the evidence when the prediction is wrong.\n\nThe paper also presents experiments on a benchmark regression task and a high-dimensional task of depth estimation, where the model is trained to output not only the final prediction but also the uncertainty associated with that prediction. The results show that the proposed method outperforms other state-of-the-art methods in terms of predictive accuracy and uncertainty estimation.\n\n1. Scalability: The paper provides experiments on a high-dimensional task of depth estimation, where the model is trained to output not only the final prediction but also the uncertainty associated with that prediction. However, the authors do not provide any information on how the model scales with the size of the input data. It would be useful to know how the number of parameters and the computational complexity of the model change with the size of the input data.\n2. Interpretability: The paper presents a method for estimating uncertainties in the model's predictions, but it does not provide any insights into the underlying mechanisms that give rise to these uncertainties. It would be useful to have a more detailed explanation of how the model learns to capture the uncertainty in the data and the model's own learning process.\n3. Robustness: The paper presents experiments on out-\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #0": "Abstract:\n\nThis paper proposes a novel approach for estimating the evidence in support of network predictions by directly learning both the inferred aleatoric uncertainty and the underlying epistemic uncertainty over its predictions. The proposed method is based on a higher-order prior distribution over the learned parameters, and it takes into account the uncertainty in the data through the use of a non-Gaussian N-I-G distribution. We demonstrate the superiority of our approach compared to existing methods in terms of predictive accuracy, uncertainty quantification, and robustness to out-of-distribution (OOD) samples. Through a combination of experiments, we show that our evidential model outperforms baselines and other methods in terms of predicting depth, accuracy, and robustness. Furthermore, we provide an analysis of the distribution of the inferred aleatoric and epistemic uncertainty, and we demonstrate that our approach can be used for real-time applications in safety-critical domains.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #1": "The paper presents a novel approach for estimating the evidence in support of network predictions and addressing the problem of out-of-distribution (OOD) samples. The authors propose an evidential model, which learns both the aleatoric and epistemic uncertainty, represented by a posterior distribution over the model's hyperparameters.\n\nThe evidential model is trained by minimizing the negative log-likelihood of the data given the inferred posterior, which is the product of the likelihood of the data given the model's parameters and the prior distribution over the parameters.\n\nThe authors argue that the evidential model is more effective than other models in terms of\u6355\u6349 the uncertainty in the data and providing a better estimate of the expected error. They demonstrate this by comparing their evidential model to several baselines, including simple and scalable predictive uncertainty estimation using deep ensembles (7.4) and prior distributions for variance parameters in hierarchical models (7.5).\n\nFurthermore, the authors show that the evidential model can capture the uncertainty in the data even for out-of-distribution samples, which are critical for the safety-critical applications where the model's predictions are needed to be reliable. They evaluate the model's performance on several datasets, including depth estimation, and demonstrate that the evidential model outperforms other models in terms of accuracy and robustness.\n\nIn conclusion, the proposed evidential model provides a more robust and accurate estimate of the uncertainty in the data compared to other models. The results of the experiments support the authors' claims and demonstrate the effectiveness of the evidential model in various domains.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #2": "This paper presents a novel approach for estimating the evidence in support of network predictions, which combines the concept of evidential uncertainty with the task of depth estimation. The authors propose a method to learn a posterior distribution over the parameters of a higher-order evidential distribution, and use this distribution to estimate the uncertainty in the depth predictions.\n\nThe proposed method is evaluated on several benchmark datasets, including the NYU Depth v2 dataset. The results demonstrate that the evidential model outperforms several baselines in terms of predictive accuracy and uncertainty. The authors also show that the evidential model can capture both aleatoric and epistemic uncertainty in the data.\n\nFrom a theoretical perspective, the proposed method can be understood as an extension of the well-known Maximum Likelihood Estimation (MLE) method. The authors use the concept of virtual observations, which allow them to estimate the posterior distribution over the model parameters while taking into account the uncertainty in the data. This is similar to the approach of Parisi (1988) for estimating the posterior distribution of a Gaussian distribution.\n\nThe authors also show that the evidential model can be used to estimate the aleatoric uncertainty in the data, which is consistent with previous work in the field of evidential inference (Soch & Allefeld, 2016). This is achieved by using the Gamma function, which is the product of the gamma function and the digamma function. The authors demonstrate that the Gamma function is a suitable prior for estimating the aleatoric uncertainty, and that it can be used to estimate the mean and variance of a Gaussian likelihood function.\n\nOverall, the proposed method is a valuable addition to the field of evidential inference, as it combines the concept of depth estimation with the task of uncertainty estimation. The results demonstrate that the evidential model can be used to estimate both aleatoric and epistemic uncertainty in the data, and that it outperforms several baselines in terms of predictive accuracy. The authors also show that the evidential model can be used to estimate the aleatoric uncertainty in the data, which is consistent with previous work in the field of evidential inference.\n ---------------------- Your Score (1~5) ----------------------\n"}