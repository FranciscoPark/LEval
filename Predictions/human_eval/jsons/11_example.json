{"input": "Introduction\nAccurate language identification (LID) is the first step in many natural language processing and machine comprehension pipelines. If the language of a piece of text is known then the appropriate downstream models like parts of speech taggers and language models can be applied as required.\nLID is further also an important step in harvesting scarce language resources. Harvested data can be used to bootstrap more accurate LID models and in doing so continually improve the quality of the harvested data. Availability of data is still one of the big roadblocks for applying data driven approaches like supervised machine learning in developing countries.\nHaving 11 official languages of South Africa has lead to initiatives (discussed in the next section) that have had positive effect on the availability of language resources for research. However, many of the South African languages are still under resourced from the point of view of building data driven models for machine comprehension and process automation.\nTable TABREF2 shows the percentages of first language speakers for each of the official languages of South Africa. These are four conjunctively written Nguni languages (zul, xho, nbl, ssw), Afrikaans (afr) and English (eng), three disjunctively written Sotho languages (nso, sot, tsn), as well as tshiVenda (ven) and Xitsonga (tso). The Nguni languages are similar to each other and harder to distinguish. The same is true of the Sotho languages.\nThis paper presents a hierarchical naive Bayesian and lexicon based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks.\nSection SECREF2 reviews existing works on the topic and summarises the remaining research problems. Section SECREF3 of the paper discusses the proposed algorithm and Section SECREF4 presents comparative results.\nRelated Works\nThe focus of this section is on recently published datasets and LID research applicable to the South African context. An in depth survey of algorithms, features, datasets, shared tasks and evaluation methods may be found in BIBREF0.\nThe datasets for the DSL 2015 & DSL 2017 shared tasks BIBREF1 are often used in LID benchmarks and also available on Kaggle . The DSL datasets, like other LID datasets, consists of text sentences labelled by language. The 2017 dataset, for example, contains 14 languages over 6 language groups with 18000 training samples and 1000 testing samples per language.\nThe recently published JW300 parallel corpus BIBREF2 covers over 300 languages with around 100 thousand parallel sentences per language pair on average. In South Africa, a multilingual corpus of academic texts produced by university students with different mother tongues is being developed BIBREF3. The WiLI-2018 benchmark dataset BIBREF4 for monolingual written natural language identification includes around 1000 paragraphs of 235 languages. A possibly useful link can also be made BIBREF5 between Native Language Identification (NLI) (determining the native language of the author of a text) and Language Variety Identification (LVI) (classification of different varieties of a single language) which opens up more datasets. The Leipzig Corpora Collection BIBREF6, the Universal Declaration of Human Rights and Tatoeba are also often used sources of data.\nThe NCHLT text corpora BIBREF7 is likely a good starting point for a shared LID task dataset for the South African languages BIBREF8. The NCHLT text corpora contains enough data to have 3500 training samples and 600 testing samples of 300+ character sentences per language. Researchers have recently started applying existing algorithms for tasks like neural machine translation in earnest to such South African language datasets BIBREF9.\nExisting NLP datasets, models and services BIBREF10 are available for South African languages. These include an LID algorithm BIBREF11 that uses a character level n-gram language model. Multiple papers have shown that 'shallow' naive Bayes classifiers BIBREF12, BIBREF8, BIBREF13, BIBREF14, SVMs BIBREF15 and similar models work very well for doing LID. The DSL 2017 paper BIBREF1, for example, gives an overview of the solutions of all of the teams that competed on the shared task and the winning approach BIBREF16 used an SVM with character n-gram, parts of speech tag features and some other engineered features. The winning approach for DSL 2015 used an ensemble naive Bayes classifier. The fasttext classifier BIBREF17 is perhaps one of the best known efficient 'shallow' text classifiers that have been used for LID .\nMultiple papers have proposed hierarchical stacked classifiers (including lexicons) that would for example first classify a piece of text by language group and then by exact language BIBREF18, BIBREF19, BIBREF8, BIBREF0. Some work has also been done on classifying surnames between Tshivenda, Xitsonga and Sepedi BIBREF20. Additionally, data augmentation BIBREF21 and adversarial training BIBREF22 approaches are potentially very useful to reduce the requirement for data.\nResearchers have investigated deeper LID models like bidirectional recurrent neural networks BIBREF23 or ensembles of recurrent neural networks BIBREF24. The latter is reported to achieve 95.12% in the DSL 2015 shared task. In these models text features can include character and word n-grams as well as informative character and word-level features learnt BIBREF25 from the training data. The neural methods seem to work well in tasks where more training data is available.\nIn summary, LID of short texts, informal styles and similar languages remains a difficult problem which is actively being researched. Increased confusion can in general be expected between shorter pieces of text and languages that are more closely related. Shallow methods still seem to work well compared to deeper models for LID. Other remaining research opportunities seem to be data harvesting, building standardised datasets and creating shared tasks for South Africa and Africa. Support for language codes that include more languages seems to be growing and discoverability of research is improving with more survey papers coming out. Paywalls also seem to no longer be a problem; the references used in this paper was either openly published or available as preprint papers.\nMethodology\nThe proposed LID algorithm builds on the work in BIBREF8 and BIBREF26. We apply a naive Bayesian classifier with character (2, 4 & 6)-grams, word unigram and word bigram features with a hierarchical lexicon based classifier.\nThe naive Bayesian classifier is trained to predict the specific language label of a piece of text, but used to first classify text as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga or Tshivenda. The scikit-learn multinomial naive Bayes classifier is used for the implementation with an alpha smoothing value of 0.01 and hashed text features.\nThe lexicon based classifier is then used to predict the specific language within a language group. For the South African languages this is done for the Nguni and Sotho groups. If the lexicon prediction of the specific language has high confidence then its result is used as the final label else the naive Bayesian classifier's specific language prediction is used as the final result. The lexicon is built over all the data and therefore includes the vocabulary from both the training and testing sets.\nThe lexicon based classifier is designed to trade higher precision for lower recall. The proposed implementation is considered confident if the number of words from the winning language is at least one more than the number of words considered to be from the language scored in second place.\nThe stacked classifier is tested against three public LID implementations BIBREF17, BIBREF23, BIBREF8. The LID implementation described in BIBREF17 is available on GitHub and is trained and tested according to a post on the fasttext blog. Character (5-6)-gram features with 16 dimensional vectors worked the best. The implementation discussed in BIBREF23 is available from https://github.com/tomkocmi/LanideNN. Following the instructions for an OSX pip install of an old r0.8 release of TensorFlow, the LanideNN code could be executed in Python 3.7.4. Settings were left at their defaults and a learning rate of 0.001 was used followed by a refinement with learning rate of 0.0001. Only one code modification was applied to return the results from a method that previously just printed to screen. The LID algorithm described in BIBREF8 is also available on GitHub.\nThe stacked classifier is also tested against the results reported for four other algorithms BIBREF16, BIBREF26, BIBREF24, BIBREF15. All the comparisons are done using the NCHLT BIBREF7, DSL 2015 BIBREF19 and DSL 2017 BIBREF1 datasets discussed in Section SECREF2.\nResults and Analysis\nThe average classification accuracy results are summarised in Table TABREF9. The accuracies reported are for classifying a piece of text by its specific language label. Classifying text only by language group or family is a much easier task as reported in BIBREF8.\nDifferent variations of the proposed classifier were evaluated. A single NB classifier (NB), a stack of two NB classifiers (NB+NB), a stack of a NB classifier and lexicon (NB+Lex) and a lexicon (Lex) by itself. A lexicon with a 50% training token dropout is also listed to show the impact of the lexicon support on the accuracy.\nFrom the results it seems that the DSL 2017 task might be harder than the DSL 2015 and NCHLT tasks. Also, the results for the implementation discussed in BIBREF23 might seem low, but the results reported in that paper is generated on longer pieces of text so lower scores on the shorter pieces of text derived from the NCHLT corpora is expected.\nThe accuracy of the proposed algorithm seems to be dependent on the support of the lexicon. Without a good lexicon a non-stacked naive Bayesian classifier might even perform better.\nThe execution performance of some of the LID implementations are shown in Table TABREF10. Results were generated on an early 2015 13-inch Retina MacBook Pro with a 2.9 GHz CPU (Turbo Boosted to 3.4 GHz) and 8GB RAM. The C++ implementation in BIBREF17 is the fastest. The implementation in BIBREF8 makes use of un-hashed feature representations which causes it to be slower than the proposed sklearn implementation. The execution performance of BIBREF23 might improve by a factor of five to ten when executed on a GPU.\nConclusion\nLID of short texts, informal styles and similar languages remains a difficult problem which is actively being researched. The proposed algorithm was evaluated on three existing datasets and compared to the implementations of three public LID implementations as well as to reported results of four other algorithms. It performed well relative to the other methods beating their results. However, the performance is dependent on the support of the lexicon.\nWe would like to investigate the value of a lexicon in a production system and how to possibly maintain it using self-supervised learning. We are investigating the application of deeper language models some of which have been used in more recent DSL shared tasks. We would also like to investigate data augmentation strategies to reduce the amount of training data that is required.\nFurther research opportunities include data harvesting, building standardised datasets and shared tasks for South Africa as well as the rest of Africa. In general, the support for language codes that include more languages seems to be growing, discoverability of research is improving and paywalls seem to no longer be a big problem in getting access to published research.", "source": "scientific_qa", "evaluation": "human", "instructions #0": "What is the approach of previous work?", "instructions #1": "Is the lexicon the same for all languages?", "instructions #2": "How do they obtain the lexicon?", "instructions #3": "What evaluation metric is used?", "instructions #4": "Which languages are similar to each other?", "instructions #5": "Which datasets are employed for South African languages LID?", "instructions #6": "Does the paper report the performance of a baseline model on South African languages LID?", "instructions #7": "Does the algorithm improve on the state-of-the-art methods?", "outputs #0": "'shallow' naive Bayes, SVM, hierarchical stacked classifiers, bidirectional recurrent neural networks", "outputs #1": "Yes", "outputs #2": "built over all the data and therefore includes the vocabulary from both the training and testing sets", "outputs #3": "average classification accuracy, execution performance", "outputs #4": "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "outputs #5": "DSL 2015, DSL 2017, JW300 parallel corpus , NCHLT text corpora", "outputs #6": "Yes", "outputs #7": "Yes", "gpt4_outputs #0": "Previous work on language identification (LID) has used methods like naive Bayes classifiers, support vector machines (SVMs), and hierarchical stacked classifiers. Some approaches have used character-level n-gram language models, parts of speech tag features, and other engineered features.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #1": "No, the lexicon is different for each language or language group.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #2": "The lexicon is built over all the data, which includes the vocabulary from both the training and testing sets.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #3": "The evaluation metric used is the average classification accuracy.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #4": "The Nguni languages (zul, xho, nbl, ssw) are similar to each other and harder to distinguish. The same is true of the Sotho languages (nso, sot, tsn).\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #5": "The datasets employed for South African languages LID are the NCHLT text corpora, DSL 2015, and DSL 2017 datasets.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #6": "Yes, the paper reports the performance of multiple variations of the proposed classifier, including a single naive Bayesian classifier (NB), a stack of two naive Bayesian classifiers (NB+NB), a stack of a naive Bayesian classifier and lexicon (NB+Lex), and a lexicon (Lex) by itself.\n ---------------------- Your Score (1~5) ----------------------\n", "gpt4_outputs #7": "Yes, the proposed algorithm performed well relative to other methods, beating their results. However, its performance is dependent on the support of the lexicon.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #0": "Previous work on language identification has used approaches such as:\nNaive Bayes classifiers using character n-grams, word n-grams and Parts of Speech tags.\n\nSupport Vector Machines (SVMs) with engineered features.\n\nHierarchical classifiers that first classify by language group and then by exact language.\n\nNeural networks like bidirectional recurrent neural networks and ensembles of recurrent neural networks.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #1": "The paper does not specify if the lexicon is the same for all languages. It mentions building a lexicon \"over all the data\", so it seems the lexicon contains words from all languages.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #2": "The paper does not specify how the lexicon is obtained. It only mentions that \"The lexicon is built over all the data and therefore includes the vocabulary from both the training and testing sets.\"\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #3": "The paper reports average classification accuracy as the evaluation metric. It reports accuracies for classifying a piece of text by its specific language label.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #4": "The paper mentions that the Nguni languages (Zulu, Xhosa, Ndebele, Swati) are similar to each other and harder to distinguish. The Sotho languages (Northern Sotho, Sotho, Tswana) are also similar to each other.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #5": "The paper evaluates the proposed algorithm on:\n\nThe NCHLT text corpora which contains Zulu, Xhosa, Afrikaans, English and other South African languages.\n\nThe DSL 2015 and DSL 2017 datasets which contain similar languages.\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #6": "Yes, the paper reports the performance of:\nA single naive Bayes (NB) classifier\nAn ensemble of 2 NB classifiers\nA lexicon-only classifier\n ---------------------- Your Score (1~5) ----------------------\n", "claude_outputs #7": "Yes, the paper reports that the proposed stacked NB and lexicon classifier \"performed well relative to the other methods beating their results.\" However, it notes that the performance depends on the quality of the lexicon.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #0": "  Previous work has focused on developing shallow naive Bayes classifiers.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #1": "  No.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #2": "  The lexicon is built over all the data and includes the vocabulary from both the training and testing sets.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #3": "  The evaluation metric used is accuracy.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #4": "  The Nguni languages (zul, xho, nbl, ssw) are similar to each other.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #5": "  The paper employs the NCHLT text corpora and the DSL 2015 & 2017 shared tasks datasets for South African languages LID.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #6": "  Yes.\n ---------------------- Your Score (1~5) ----------------------\n", "llama2-13b-chat-4k_pred #7": "  Yes.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #0": "\n\nThe approach of previous work in the field of language identification (LID) is to use algorithms such as naive Bayes classifiers, support vector machines (SVMs), and ensemble models to classify short pieces of text into one of the 11 official languages of South Africa. These algorithms are often trained on existing datasets, such as the DSL 2015 & 2017 shared tasks, and evaluated using metrics such as accuracy and precision. The focus of this paper is on a new hierarchical approach to LID, which uses a combination of a naive Bayes classifier and a lexicon-based classifier. The algorithm is evaluated against previous approaches using test sets from previous works on South African languages and the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The paper also reviews existing works on the topic and discusses the proposed algorithm in Section SECREF4.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #1": "\n\nThe document discusses the problem of accurate language identification (LID) in South Africa, which is the first step in many natural language processing and machine comprehension pipelines. The document presents a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The document also reviews existing works on the topic and summarizes the remaining research problems. The focus of this section is on recently published datasets and LID research applicable to the South African context. The document also mentions that the NCHLT text corpora is likely a good starting point for a shared LID task dataset for the South African languages.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #2": "\n\nThe paper presents a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The paper reviews existing works on the topic and summarizes the remaining research problems. The focus of this section is on recently published datasets and LID research applicable to the South African context. The datasets for the DSL 2015 & DSL 2017 shared tasks are often used in LID benchmarks and also available on Kaggle. The JW300 parallel corpus covers over 300 languages with around 100 thousand parallel sentences per language pair on average. The WiLI-2018 benchmark dataset includes around 1000 paragraphs of 235 languages. The Leipzig Corpora Collection, the Universal Declaration of Human Rights and Tatoeba are also often used sources of data. The NCHLT text corpora is likely a good starting point for a shared LID task dataset for the South African languages. The NCHLT text corpora contains enough data to have 3500 training samples and 600 testing samples of 300+ character sentences per language. The paper also discusses the proposed algorithm and comparative results. The existing NLP datasets, models and services are available for South African languages. These include an LID algorithm that uses a character level n-gram language model. The DSL 2017 paper gives an overview of the solutions of all of the teams that competed on the shared task and the winning approach used an SVM with character n-gram, parts of speech tag features and some other engineered features. The winning approach for DSL 2015 used an ensemble naive Bayes classifier. The fasttext classifier is one of the best known efficient 'shallow' text classifiers that have been used for LID.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #3": "\n\nThe paper presents a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The evaluation metric used is not specified in the document.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #4": "\n\nThe languages in South Africa are similar to each other, especially the Nguni and Sotho languages. The Nguni languages are similar to each other and hard to distinguish, and the same is true of the Sotho languages.\n\nMy spanish answer is:\n\nLas lenguas en Sud\u00e1frica son similares entre s\u00ed, especialmente los lenguajes Nguni y Sotho. Los lenguajes Nguni son similares entre s\u00ed y dif\u00edciles de distinguir, lo mismo ocurre con los lenguajes Sotho.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #5": "\n\nThe paper presents a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The paper reviews existing works on the topic and summarizes the remaining research problems. The focus of this section is on recently published datasets and LID research applicable to the South African context. The datasets for the DSL 2015 & DSL 2017 shared tasks are often used in LID benchmarks and also available on Kaggle. The JW300 parallel corpus covers over 300 languages with around 100 thousand parallel sentences per language pair on average. The WiLI-2018 benchmark dataset for monolingual written natural language identification includes around 1000 paragraphs of 235 languages. The Leipzig Corpora Collection, the Universal Declaration of Human Rights and Tatoeba are also often used sources of data. The NCHLT text corpora is likely a good starting point for a shared LID task dataset for the South African languages. The NCHLT text corpora contains enough data to have 3500 training samples and 600 testing samples of 300+ character sentences per language. The paper also discusses the use of existing algorithms for tasks like neural machine translation in earnest to such South African language datasets.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #6": "\n\nYes, the paper reports the performance of a baseline model on South African languages LID. The paper proposes a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The paper also discusses the proposed algorithm and presents comparative results.\n ---------------------- Your Score (1~5) ----------------------\n", "vicuna-7b-2k_pred #7": "\n\nThe algorithm presented in this paper is a hierarchical naive Bayesian and lexicon-based classifier for short pieces of text (15-20 characters) in South African languages. It is evaluated against existing approaches using test sets from previous works on South African languages and the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks. The paper also reviews existing works on the topic and discusses the proposed algorithm. The focus is on recently published datasets and LID research applicable to the South African context. The Leipzig Corpora Collection, the Universal Declaration of Human Rights, and Tatoeba are also often used sources of data. Researchers have started applying existing algorithms for tasks like neural machine translation to South African language datasets.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #0": "Previous work on language identification (LID) has focused on developing algorithms, features, datasets, and evaluation methods applicable to the South African context. Shallow methods such as naive Bayes classifiers and SVMs have been shown to work well for LID. Some researchers have proposed hierarchical stacked classifiers and lexicon-based classifiers to improve accuracy. Deeper models like bidirectional recurrent neural networks have also been explored. However, LID of short texts, informal styles, and similar languages remains a challenging problem.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #1": "No, the lexicon is not the same for all languages. The lexicon is built over all the data, including both the training and testing sets, and is used to predict the specific language within a language group.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #2": "The lexicon used in the proposed LID algorithm is obtained by building it over all the data, including both the training and testing sets. The lexicon is designed to trade higher precision for lower recall. It is considered confident if the number of words from the winning language is at least one more than the number of words considered to be from the language scored in second place. This approach helps in predicting the specific language within a language group. The lexicon is an important component of the algorithm and its support is crucial for achieving accurate results.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #3": "The evaluation metric used is classification accuracy.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #4": "The Nguni languages are similar to each other and harder to distinguish. The same is true of the Sotho languages.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #5": "The datasets employed for South African languages LID include the DSL 2015 and DSL 2017 shared tasks datasets, the recently published JW300 parallel corpus, a multilingual corpus of academic texts produced by university students in South Africa, the WiLI-2018 benchmark dataset, the Leipzig Corpora Collection, the Universal Declaration of Human Rights, and Tatoeba.\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #6": "Yes\n ---------------------- Your Score (1~5) ----------------------\n", "turbo-16k-0613_pred #7": "Yes.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #0": "1. The document discusses accurate language identification (LID) as the first step in natural language processing and machine comprehension pipelines.\n2. LID is crucial for harvesting scarce language resources, which can be used to improve the quality of harvested data.\n3. South Africa has 11 official languages, leading to initiatives that have improved the availability of language resources for research.\n4. The paper presents a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text.\n5. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks.\n6. The related works section reviews recently published datasets and LID research applicable to the South African context.\n7. The methodology involves applying a naive Bayesian classifier with character (2, 4 & 6)-grams, word unigram and word bigram features, and a hierarchical lexicon-based classifier.\n8. The proposed algorithm performs well relative to other methods, but its performance is dependent on the support of the lexicon.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #1": "1. The lexicon is not the same for all languages. It is built over all the data and includes the vocabulary from both the training and testing sets.\n2. The lexicon-based classifier is designed to trade higher precision for lower recall.\n3. The lexicon is built using all the data and includes the vocabulary from both the training and testing sets.\n4. The lexicon-based classifier is used to predict the specific language within a language group.\n5. The lexicon is used to classify the text as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga or Tshivenda.\n6. The lexicon is used to predict the specific language within a language group.\n7. The lexicon is designed to trade higher precision for lower recall.\n8. The lexicon is built over all the data and includes the vocabulary from both the training and testing sets.\n9. The lexicon is used to classify the text as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga or Tshivenda.\n10. The lexicon is used to predict the specific language within a language group.\n11. The lexicon is designed to trade higher precision for lower recall.\n12. The lexicon is built over all the data and includes the vocabulary from both the training and testing sets.\n13. The lexicon is used to classify the text as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga or Tshivenda.\n14. The lexicon is used to predict the specific language within a language group.\n15. The lexicon is designed to trade higher precision for lower recall.\n16. The lexicon is built over all the data and includes the vocabulary from both the training and testing sets.\n17. The lexicon is used to classify the text as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga or Tshivenda.\n18. The lexicon is used to predict the specific language within a language group.\n19. The lexicon is designed to trade higher precision for lower recall.\n20. The\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #2": "1. The authors obtain the lexicon by training a classifier on a large corpus of text data in the target languages. The classifier is trained to predict the specific language label of a piece of text, but first classifies it as belonging to either the Nguni family, the Sotho family, English, Afrikaans, Xitsonga, or Tshivenda. The lexicon is then used to predict the specific language within a language group.\n2. The lexicon is built over all the data, including the training and testing sets, and includes the vocabulary from both sets. The lexicon is designed to trade higher precision for lower recall. The proposed implementation is considered confident if the number of words from the winning language is at least one more than the number of words considered to be from the language scored in second place.\n3. The authors evaluate the performance of the proposed algorithm on three existing datasets and compare it to the implementations of three public LID implementations as well as to reported results of four other algorithms. The algorithm performed well relative to the other methods, beating their results. However, the performance is dependent on the support of the lexicon.\n4. The authors would like to investigate the value of a lexicon in a production system and how to possibly maintain it using self-supervised learning. They are also investigating the application of deeper language models, some of which have been used in more recent DSL shared tasks. Additionally, the authors are exploring data augmentation strategies to reduce the amount of training data that is required.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #3": "1. The evaluation metric used is accuracy.\n2. The suggested output length is around 5 words.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #4": "1. The Nguni languages are similar to each other and harder to distinguish.\n2. The Sotho languages are also similar to each other.\n3. English and Afrikaans are relatively easy to distinguish from the other languages.\n4. Xitsonga and Tshivenda are more distinct from the other languages.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #5": "1. DSL 2015 & DSL 2017 shared tasks: BIBREF1\n2. JW300 parallel corpus: BIBREF2\n3. WiLI-2018 benchmark dataset: BIBREF4\n4. NCHLT text corpora: BIBREF7\n5. NLP datasets, models, and services: BIBREF10\n6. LID algorithm using character level n-gram language model: BIBREF11\n7. Multiple papers on shallow naive Bayes classifiers: BIBREF12, BIBREF8, BIBREF13, BIBREF14, BIBREF15\n8. Fasttext classifier: BIBREF17\n9. Bidirectional recurrent neural networks: BIBREF23\n10. Ensembles of recurrent neural networks: BIBREF24\n11. Lexicon based classifier: BIBREF8, BIBREF26\n12. Stacked classifier: BIBREF17, BIBREF23, BIBREF8\n13. Execution performance of LID implementations: BIBREF10\n14. Dependence of proposed algorithm's accuracy on lexicon support: BIBREF9\n15. Investigation of deeper language models, self-supervised learning, data augmentation strategies, and shared tasks for South Africa and Africa.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #6": "1. The paper reports the performance of a baseline model on South African languages LID. The model uses a character (2, 4 & 6)-grams, word unigram and word bigram features with a hierarchical lexicon-based classifier. The performance of the baseline model is compared to three public LID implementations and four other algorithms on three datasets: NCHLT, DSL 2015, and DSL 2017.\n ---------------------- Your Score (1~5) ----------------------\n", "longchat-13b-16k-flash_pred #7": "1. The proposed LID algorithm builds on the work in BIBREF8 and BIBREF26.\n2. The algorithm is a hierarchical naive Bayesian and lexicon-based classifier for LID of short pieces of text of 15-20 characters long.\n3. The algorithm is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the Discriminating between Similar Languages (DSL) 2015 and 2017 shared tasks.\n4. The table shows the percentages of first language speakers for each of the official languages of South Africa.\n5. The DSL 2015 & DSL 2017 shared tasks BIBREF1 are often used in LID benchmarks and also available on Kaggle.\n6. The JW300 parallel corpus BIBREF2 covers over 300 languages with around 100 thousand parallel sentences per language pair on average.\n7. The WiLI-2018 benchmark dataset BIBREF4 for monolingual written natural language identification includes around 1000 paragraphs of 235 languages.\n8. The NCHLT text corpora BIBREF7 is likely a good starting point for a shared LID task dataset for the South African languages BIBREF8.\n9. The NLP datasets, models and services BIBREF10 are available for South African languages.\n10. The proposed LID algorithm improves on the state-of-the-art methods for LID of short texts, informal styles, and similar languages.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #0": "The approach of previous work is to use a hierarchical naive Bayesian and lexicon-based classifier for short pieces of text of 15-20 characters in 11 official languages of South Africa. This classifier is evaluated against recent approaches using existing test sets from previous works on South African languages and the DSL 2015 and DSL 2017 shared tasks. The algorithm is found to perform well relative to the other methods, but its performance is dependent on the support of the lexicon.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #1": "No, the lexicon is not the same for all languages.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #2": "The LID algorithm proposed in this document is a hierarchical naive Bayesian and lexicon-based classifier for short pieces of text of 15-20 characters long. It is evaluated against recent approaches using existing test sets from previous works on South African languages as well as the DSL 2015 and DSL 2017 shared tasks. The algorithm builds on the work in BIBREF8 and BIBREF26. It applies a naive Bayesian classifier with character (2, 4 & 6)-grams, word unigram and word bigram features with a hierarchical lexicon based classifier. The lexicon-based classifier is then used to predict the specific language within a language group. The average classification accuracy results are summarized in Table TABREF9. The accuracy of the proposed algorithm seems to be dependent on the support of the lexicon.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #3": "The evaluation metric used in this paper is accuracy.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #4": "The languages are similar to each other.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #5": "The datasets used for South African languages LID include the DSL 2015 & DSL 2017 shared tasks, the JW300 parallel corpus, the NCHLT text corpora, and the Leipzig Corpora Collection.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #6": "Yes.\n ---------------------- Your Score (1~5) ----------------------\n", "chatglm2-6b-8k_pred #7": "Yes.\n ---------------------- Your Score (1~5) ----------------------\n"}